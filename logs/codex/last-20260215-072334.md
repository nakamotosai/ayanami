已完成并发改造，其他逻辑保持不变。

变更点：
- `skills/news-briefing/scripts/fetch_news.py:3` 新增 `concurrent.futures` 导入。
- `skills/news-briefing/scripts/fetch_news.py:115` 将 `collect(region)` 改为 `collect(region, concurrency=6)`，并用 `ThreadPoolExecutor(max_workers=concurrency)` 并发抓取各 feed。
- `skills/news-briefing/scripts/fetch_news.py:121` 每个抓取仍走原来的 `fetch_items()`，内部继续使用 `urllib.request.urlopen(..., timeout=20)`。
- `skills/news-briefing/scripts/fetch_news.py:193` 新增命令行参数 `--concurrency`（默认 `6`），并传入 `collect()`。

验证结果：
- 已运行：`python3 skills/news-briefing/scripts/fetch_news.py --top 10 --format json`
- 退出码 `0`，输出为合法 JSON：`[]`
- 额外验证：`python3 skills/news-briefing/scripts/fetch_news.py --top 1 --format json --concurrency 3`
- 退出码 `0`，输出同样为合法 JSON：`[]`